{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a703303e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:08:58.504316Z",
     "iopub.status.busy": "2023-11-29T07:08:58.503683Z",
     "iopub.status.idle": "2023-11-29T07:09:02.956804Z",
     "shell.execute_reply": "2023-11-29T07:09:02.955921Z"
    },
    "id": "GvNtUKwrils9",
    "papermill": {
     "duration": 4.463593,
     "end_time": "2023-11-29T07:09:02.959244",
     "exception": false,
     "start_time": "2023-11-29T07:08:58.495651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD,Adam,lr_scheduler\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision import transforms,models\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8cfcc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:09:02.975225Z",
     "iopub.status.busy": "2023-11-29T07:09:02.974759Z",
     "iopub.status.idle": "2023-11-29T07:09:02.979360Z",
     "shell.execute_reply": "2023-11-29T07:09:02.978431Z"
    },
    "id": "aaCh7xP_Gauj",
    "papermill": {
     "duration": 0.014878,
     "end_time": "2023-11-29T07:09:02.981376",
     "exception": false,
     "start_time": "2023-11-29T07:09:02.966498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69e9442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:09:02.996100Z",
     "iopub.status.busy": "2023-11-29T07:09:02.995778Z",
     "iopub.status.idle": "2023-11-29T07:09:06.425767Z",
     "shell.execute_reply": "2023-11-29T07:09:06.424669Z"
    },
    "id": "aV45WYMWipjn",
    "outputId": "6dfcd127-f73d-4e93-815a-f07d2a803b72",
    "papermill": {
     "duration": 3.440446,
     "end_time": "2023-11-29T07:09:06.428638",
     "exception": false,
     "start_time": "2023-11-29T07:09:02.988192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(p=.40),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "traindata = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "trainset,valset = random_split(traindata,[42000,8000])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64,shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeee4435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:09:06.444981Z",
     "iopub.status.busy": "2023-11-29T07:09:06.444390Z",
     "iopub.status.idle": "2023-11-29T07:09:10.033854Z",
     "shell.execute_reply": "2023-11-29T07:09:10.032588Z"
    },
    "id": "ji0jbMNti0QA",
    "outputId": "5a62128e-61b6-4255-b126-5e79e1d3f173",
    "papermill": {
     "duration": 3.600121,
     "end_time": "2023-11-29T07:09:10.036321",
     "exception": false,
     "start_time": "2023-11-29T07:09:06.436200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 131MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['base', 'drop', 'final']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        self.base = nn.Sequential(*list(base.children())[:-1])\n",
    "        in_features = base.fc.in_features\n",
    "        self.drop = nn.Dropout()\n",
    "        self.final = nn.Linear(in_features,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.base(x)\n",
    "        x = self.drop(x.view(-1,self.final.in_features))\n",
    "        return self.final(x)\n",
    "    \n",
    "model = Model().cuda()\n",
    "[x for x,y in model.named_children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6bc2799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:09:10.054221Z",
     "iopub.status.busy": "2023-11-29T07:09:10.053547Z",
     "iopub.status.idle": "2023-11-29T07:09:10.060005Z",
     "shell.execute_reply": "2023-11-29T07:09:10.059058Z"
    },
    "id": "5YLRXF0WjRvw",
    "papermill": {
     "duration": 0.017766,
     "end_time": "2023-11-29T07:09:10.062168",
     "exception": false,
     "start_time": "2023-11-29T07:09:10.044402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "param_groups = [\n",
    "    {'params':model.base.parameters(),'lr':.0001},\n",
    "    {'params':model.final.parameters(),'lr':.001}\n",
    "]\n",
    "optimizer = Adam(param_groups)\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "states = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f82d149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:09:10.079277Z",
     "iopub.status.busy": "2023-11-29T07:09:10.078644Z",
     "iopub.status.idle": "2023-11-29T07:36:14.399955Z",
     "shell.execute_reply": "2023-11-29T07:36:14.398923Z"
    },
    "id": "2fY3WFQdjUey",
    "outputId": "5c01ad04-7f5c-4765-bc7c-b8c0a2379498",
    "papermill": {
     "duration": 1624.332067,
     "end_time": "2023-11-29T07:36:14.402033",
     "exception": false,
     "start_time": "2023-11-29T07:09:10.069966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1: 0.5050055582977476,Train Acc:82.69047619047619%\n",
      "Val accuracy:89.2875%\n",
      "Train loss 2: 0.22471497406846,Train Acc:92.38095238095238%\n",
      "Val accuracy:93.4%\n",
      "Train loss 3: 0.19279915895348504,Train Acc:93.57142857142857%\n",
      "Val accuracy:93.275%\n",
      "Train loss 4: 0.1886163093390919,Train Acc:93.69761904761904%\n",
      "Val accuracy:93.575%\n",
      "Train loss 5: 0.1867631315929549,Train Acc:93.75%\n",
      "Val accuracy:93.4%\n",
      "Train loss 6: 0.19008417707397823,Train Acc:93.65%\n",
      "Val accuracy:93.1125%\n",
      "Train loss 7: 0.19087958645252953,Train Acc:93.62142857142857%\n",
      "Val accuracy:93.575%\n",
      "Train loss 8: 0.18828718749682108,Train Acc:93.72619047619048%\n",
      "Val accuracy:93.3%\n",
      "Train loss 9: 0.18838404362258457,Train Acc:93.5904761904762%\n",
      "Val accuracy:93.525%\n",
      "Train loss 10: 0.190041633838699,Train Acc:93.68571428571428%\n",
      "Val accuracy:93.225%\n",
      "Finished Training\n",
      "CPU times: user 40min 13s, sys: 2min 54s, total: 43min 8s\n",
      "Wall time: 27min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_val_acc = -1000\n",
    "best_val_model = None\n",
    "for epoch in range(10):  \n",
    "    model.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(),labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        out = torch.argmax(outputs.detach(),dim=1)\n",
    "        assert out.shape==labels.shape\n",
    "        running_acc += (labels==out).sum().item()\n",
    "    print(f\"Train loss {epoch+1}: {running_loss/len(trainset)},Train Acc:{running_acc*100/len(trainset)}%\")\n",
    "    \n",
    "    correct = 0\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in valloader:\n",
    "            out = model(inputs.cuda()).cpu()\n",
    "            out = torch.argmax(out,dim=1)\n",
    "            acc = (out==labels).sum().item()\n",
    "            correct += acc\n",
    "    print(f\"Val accuracy:{correct*100/len(valset)}%\")\n",
    "    if correct>best_val_acc:\n",
    "        best_val_acc = correct\n",
    "        best_val_model = deepcopy(model.state_dict())\n",
    "    lr_scheduler.step()\n",
    "#     break\n",
    "print('Finished Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc41372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:14.421042Z",
     "iopub.status.busy": "2023-11-29T07:36:14.420534Z",
     "iopub.status.idle": "2023-11-29T07:36:14.428027Z",
     "shell.execute_reply": "2023-11-29T07:36:14.427043Z"
    },
    "id": "uM16_Ktdfo8w",
    "outputId": "f8f8bd6f-173c-41dd-e921-36b4f794e65c",
    "papermill": {
     "duration": 0.019331,
     "end_time": "2023-11-29T07:36:14.430361",
     "exception": false,
     "start_time": "2023-11-29T07:36:14.411030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (base): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (final): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be0bb0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:14.451185Z",
     "iopub.status.busy": "2023-11-29T07:36:14.450548Z",
     "iopub.status.idle": "2023-11-29T07:36:14.523052Z",
     "shell.execute_reply": "2023-11-29T07:36:14.522117Z"
    },
    "papermill": {
     "duration": 0.085428,
     "end_time": "2023-11-29T07:36:14.525138",
     "exception": false,
     "start_time": "2023-11-29T07:36:14.439710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 42.730MB\n"
     ]
    }
   ],
   "source": [
    "# obtain how large it is\n",
    "torch.save(model.state_dict(), './resnet18_ori.pth')\n",
    "size_model = os.path.getsize('./resnet18_ori.pth')\n",
    "print('model size: {:.3f}MB'.format(size_model/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82889580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:14.591752Z",
     "iopub.status.busy": "2023-11-29T07:36:14.591391Z",
     "iopub.status.idle": "2023-11-29T07:36:14.596653Z",
     "shell.execute_reply": "2023-11-29T07:36:14.595621Z"
    },
    "id": "qxQVZ72jjss4",
    "papermill": {
     "duration": 0.064276,
     "end_time": "2023-11-29T07:36:14.598812",
     "exception": false,
     "start_time": "2023-11-29T07:36:14.534536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = len(testset)\n",
    "timings=np.zeros((repetitions,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bc30df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:14.620488Z",
     "iopub.status.busy": "2023-11-29T07:36:14.620198Z",
     "iopub.status.idle": "2023-11-29T07:36:34.402158Z",
     "shell.execute_reply": "2023-11-29T07:36:34.401000Z"
    },
    "id": "xt_mkVxbjnYc",
    "outputId": "0748d3d8-85e4-40b8-ab6d-a12edfbc647f",
    "papermill": {
     "duration": 19.795252,
     "end_time": "2023-11-29T07:36:34.404156",
     "exception": false,
     "start_time": "2023-11-29T07:36:14.608904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean prediction latency: 1.9767248046875\n",
      "Test accuracy: 94.15%\n",
      "CPU times: user 32 s, sys: 3.51 s, total: 35.5 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "model.load_state_dict(best_val_model)\n",
    "model.train(False)\n",
    "with torch.no_grad():\n",
    "    starter.record()\n",
    "    for inputs,labels in testloader:\n",
    "        out = model(inputs.cuda()).cpu()\n",
    "        out = torch.argmax(out,dim=1)\n",
    "        acc = (out==labels).sum().item()\n",
    "        correct += acc\n",
    "    ender.record()\n",
    "    torch.cuda.synchronize()\n",
    "    curr_time = starter.elapsed_time(ender)\n",
    "    timings[epoch] = curr_time\n",
    "    # correct += acc\n",
    "mean_syn = np.sum(timings) / repetitions\n",
    "std_syn = np.std(timings)\n",
    "print(f'mean prediction latency: {mean_syn}')\n",
    "print(f\"Test accuracy: {correct*100/len(testset)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb42cd",
   "metadata": {
    "id": "4PYUWAl_1H5J",
    "papermill": {
     "duration": 0.009005,
     "end_time": "2023-11-29T07:36:34.422824",
     "exception": false,
     "start_time": "2023-11-29T07:36:34.413819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dynamic quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3f639e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:34.444520Z",
     "iopub.status.busy": "2023-11-29T07:36:34.444180Z",
     "iopub.status.idle": "2023-11-29T07:36:34.548944Z",
     "shell.execute_reply": "2023-11-29T07:36:34.547944Z"
    },
    "id": "rhFft2TmFvMs",
    "outputId": "54bd1c7c-c840-4894-a724-ecc242079862",
    "papermill": {
     "duration": 0.11841,
     "end_time": "2023-11-29T07:36:34.551291",
     "exception": false,
     "start_time": "2023-11-29T07:36:34.432881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (base): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (final): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "# state_dict = torch.load('./checkpoint.pth', map_location=\"cpu\")\n",
    "# print(state_dict.keys())\n",
    "# model.load_state_dict(state_dict)\n",
    "model.to(cpu_device)\n",
    "# Make a copy of the model for layer fusion\n",
    "fused_model = copy.deepcopy(model)\n",
    "\n",
    "model.eval()\n",
    "# The model has to be switched to evaluation mode before any layer fusion.\n",
    "# Otherwise the quantization will not work correctly.\n",
    "fused_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d120f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:34.571424Z",
     "iopub.status.busy": "2023-11-29T07:36:34.571081Z",
     "iopub.status.idle": "2023-11-29T07:36:34.656967Z",
     "shell.execute_reply": "2023-11-29T07:36:34.656058Z"
    },
    "id": "BNk1ng97ahNv",
    "outputId": "4139ed7f-f2ff-4752-8f63-543738c74161",
    "papermill": {
     "duration": 0.098833,
     "end_time": "2023-11-29T07:36:34.659341",
     "exception": false,
     "start_time": "2023-11-29T07:36:34.560508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (base): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (final): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a quantized model instance\n",
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model,  # the original model\n",
    "    {torch.nn.Sequential, torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8)  # the target dtype for quantized weights\n",
    "model_int8.to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a04cedd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:34.680431Z",
     "iopub.status.busy": "2023-11-29T07:36:34.680122Z",
     "iopub.status.idle": "2023-11-29T07:36:34.684026Z",
     "shell.execute_reply": "2023-11-29T07:36:34.683165Z"
    },
    "id": "TXqV21CXVkqt",
    "outputId": "3f2b8624-6023-4e4a-a226-d18863b133aa",
    "papermill": {
     "duration": 0.01655,
     "end_time": "2023-11-29T07:36:34.685925",
     "exception": false,
     "start_time": "2023-11-29T07:36:34.669375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainloader.__len__()\n",
    "# len(trainset)\n",
    "# testloader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c2b20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:34.706743Z",
     "iopub.status.busy": "2023-11-29T07:36:34.706472Z",
     "iopub.status.idle": "2023-11-29T07:36:34.711909Z",
     "shell.execute_reply": "2023-11-29T07:36:34.711088Z"
    },
    "id": "9_mxq34UHEFx",
    "outputId": "8c8d7770-609a-4a50-aad9-260da5d3258d",
    "papermill": {
     "duration": 0.018133,
     "end_time": "2023-11-29T07:36:34.713793",
     "exception": false,
     "start_time": "2023-11-29T07:36:34.695660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdde00cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:36:34.735760Z",
     "iopub.status.busy": "2023-11-29T07:36:34.735450Z",
     "iopub.status.idle": "2023-11-29T07:40:09.466518Z",
     "shell.execute_reply": "2023-11-29T07:40:09.465458Z"
    },
    "id": "y11BOFF934Ek",
    "outputId": "054b6664-a23c-426d-a3ec-e2851ff6593a",
    "papermill": {
     "duration": 214.754926,
     "end_time": "2023-11-29T07:40:09.478724",
     "exception": false,
     "start_time": "2023-11-29T07:36:34.723798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 94.6396%\n",
      "CPU times: user 5min 27s, sys: 1min 40s, total: 7min 8s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batches=100\n",
    "number_of_testing_data=(len(testset)/testloader.__len__())*batches\n",
    "correct = 0\n",
    "# model.load_state_dict(best_val_model)\n",
    "model_int8.train(False)\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in testloader:\n",
    "        if i ==batches: break\n",
    "        out = model_int8(inputs).cpu()\n",
    "        out = torch.argmax(out,dim=1)\n",
    "        acc = (out==labels).sum().item()\n",
    "        correct += acc\n",
    "        i+=1\n",
    "print(f\"Test accuracy: {correct*100/number_of_testing_data}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e13c5d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:40:09.499695Z",
     "iopub.status.busy": "2023-11-29T07:40:09.499414Z",
     "iopub.status.idle": "2023-11-29T07:40:09.568042Z",
     "shell.execute_reply": "2023-11-29T07:40:09.566961Z"
    },
    "id": "YtiEHgHrk2zX",
    "outputId": "5e4f3058-6bf4-402d-ee52-e040977d0ae1",
    "papermill": {
     "duration": 0.081515,
     "end_time": "2023-11-29T07:40:09.570241",
     "exception": false,
     "start_time": "2023-11-29T07:40:09.488726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 42.715MB\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_int8.state_dict(), './resnet18_aft_dy_int8.pth')\n",
    "size_int8=os.path.getsize('./resnet18_aft_dy_int8.pth')\n",
    "print('model size: {:.3f}MB'.format(size_int8/1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58818a04",
   "metadata": {
    "papermill": {
     "duration": 0.009624,
     "end_time": "2023-11-29T07:40:09.589936",
     "exception": false,
     "start_time": "2023-11-29T07:40:09.580312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Static quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a3694d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:40:09.610974Z",
     "iopub.status.busy": "2023-11-29T07:40:09.610601Z",
     "iopub.status.idle": "2023-11-29T07:40:10.501971Z",
     "shell.execute_reply": "2023-11-29T07:40:10.501031Z"
    },
    "papermill": {
     "duration": 0.904271,
     "end_time": "2023-11-29T07:40:10.504123",
     "exception": false,
     "start_time": "2023-11-29T07:40:09.599852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1209: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (base): Module(\n",
       "    (0): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=1.0, zero_point=0, padding=(3, 3))\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (drop): QuantizedDropout(p=0.5, inplace=False)\n",
       "  (final): QuantizedLinear(in_features=512, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "import torch.quantization.quantize_fx as quantize_fx\n",
    "import copy\n",
    "\n",
    "model_to_quantize = copy.deepcopy(model).to(cpu_device)\n",
    "qconfig_mapping = QConfigMapping().set_global(torch.quantization.get_default_qconfig('fbgemm'))\n",
    "model_to_quantize.eval()\n",
    "# prepare\n",
    "model_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_mapping, input).to(cpu_device)\n",
    "# calibrate (not shown)\n",
    "# quantize\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared).to(cpu_device)\n",
    "\n",
    "model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e162e4e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:40:10.525778Z",
     "iopub.status.busy": "2023-11-29T07:40:10.525493Z",
     "iopub.status.idle": "2023-11-29T07:41:54.237182Z",
     "shell.execute_reply": "2023-11-29T07:41:54.235971Z"
    },
    "papermill": {
     "duration": 103.73499,
     "end_time": "2023-11-29T07:41:54.249358",
     "exception": false,
     "start_time": "2023-11-29T07:40:10.514368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 93.9488%\n",
      "CPU times: user 3min 21s, sys: 5.9 s, total: 3min 27s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batches=100\n",
    "number_of_testing_data=(len(testset)/testloader.__len__())*batches\n",
    "correct = 0\n",
    "\n",
    "model_quantized.train(False)\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in testloader:\n",
    "        if i ==batches: break\n",
    "        out = model_quantized(inputs).cpu()\n",
    "        out = torch.argmax(out,dim=1)\n",
    "        acc = (out==labels).sum().item()\n",
    "        correct += acc\n",
    "        i+=1\n",
    "print(f\"Test accuracy: {correct*850/number_of_testing_data}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db8c9c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:41:54.271209Z",
     "iopub.status.busy": "2023-11-29T07:41:54.270887Z",
     "iopub.status.idle": "2023-11-29T07:41:54.362537Z",
     "shell.execute_reply": "2023-11-29T07:41:54.361520Z"
    },
    "papermill": {
     "duration": 0.104853,
     "end_time": "2023-11-29T07:41:54.364504",
     "exception": false,
     "start_time": "2023-11-29T07:41:54.259651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 10.790MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "torch.save(model_quantized.state_dict(), './checkpoint_static_quantized.pth')\n",
    "size_static_quantized_in_mb=os.path.getsize(\"./checkpoint_static_quantized.pth\")/1024**2\n",
    "print('model size: {:.3f}MB'.format(size_static_quantized_in_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd695721",
   "metadata": {
    "papermill": {
     "duration": 0.010439,
     "end_time": "2023-11-29T07:41:54.385509",
     "exception": false,
     "start_time": "2023-11-29T07:41:54.375070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 11102,
     "sourceId": 15444,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1980.977705,
   "end_time": "2023-11-29T07:41:56.022235",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-29T07:08:55.044530",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
