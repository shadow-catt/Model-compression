{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa69998a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:12:48.576437Z",
     "iopub.status.busy": "2023-11-29T07:12:48.575731Z",
     "iopub.status.idle": "2023-11-29T07:12:52.815777Z",
     "shell.execute_reply": "2023-11-29T07:12:52.814828Z"
    },
    "papermill": {
     "duration": 4.256234,
     "end_time": "2023-11-29T07:12:52.818368",
     "exception": false,
     "start_time": "2023-11-29T07:12:48.562134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg16\n",
    "import copy\n",
    "import tqdm\n",
    "import os\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563b2737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:12:52.842305Z",
     "iopub.status.busy": "2023-11-29T07:12:52.841265Z",
     "iopub.status.idle": "2023-11-29T07:12:56.380702Z",
     "shell.execute_reply": "2023-11-29T07:12:56.379378Z"
    },
    "papermill": {
     "duration": 3.554457,
     "end_time": "2023-11-29T07:12:56.383528",
     "exception": false,
     "start_time": "2023-11-29T07:12:52.829071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.Pad(4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomGrayscale(),\n",
    "     transforms.RandomCrop(32, padding=4),\n",
    "])\n",
    " \n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    ")\n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "trainset = torchvision.datasets.CIFAR10(root='/data', train=True, download=True, transform=transform_train)\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=24, shuffle=True)\n",
    " \n",
    "testset = torchvision.datasets.CIFAR10(root='/data', train=False, download=False, transform=transform_test)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size=24, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bbb169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:12:56.406357Z",
     "iopub.status.busy": "2023-11-29T07:12:56.405937Z",
     "iopub.status.idle": "2023-11-29T07:12:56.414594Z",
     "shell.execute_reply": "2023-11-29T07:12:56.413410Z"
    },
    "papermill": {
     "duration": 0.022962,
     "end_time": "2023-11-29T07:12:56.417069",
     "exception": false,
     "start_time": "2023-11-29T07:12:56.394107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "total = 0\n",
    "accuracy_rate = []\n",
    " \n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0  # 预测正确的图片数\n",
    "    total = 0  # total number of pictures\n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).to(device)\n",
    "            outputs = outputs.cpu()\n",
    "            outputarr = outputs.numpy()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracy_rate.append(accuracy)\n",
    "    print(f'Accuracy is:{accuracy}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cceb6004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:12:56.440505Z",
     "iopub.status.busy": "2023-11-29T07:12:56.439839Z",
     "iopub.status.idle": "2023-11-29T07:13:03.633787Z",
     "shell.execute_reply": "2023-11-29T07:13:03.632544Z"
    },
    "papermill": {
     "duration": 7.209719,
     "end_time": "2023-11-29T07:13:03.637143",
     "exception": false,
     "start_time": "2023-11-29T07:12:56.427424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:05<00:00, 110MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab6598",
   "metadata": {
    "papermill": {
     "duration": 0.015278,
     "end_time": "2023-11-29T07:13:03.668634",
     "exception": false,
     "start_time": "2023-11-29T07:13:03.653356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The training of the model\n",
    "Since we need to load it, here we ignore the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c32a16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:13:03.703988Z",
     "iopub.status.busy": "2023-11-29T07:13:03.703012Z",
     "iopub.status.idle": "2023-11-29T07:13:03.710747Z",
     "shell.execute_reply": "2023-11-29T07:13:03.709358Z"
    },
    "papermill": {
     "duration": 0.031879,
     "end_time": "2023-11-29T07:13:03.715835",
     "exception": false,
     "start_time": "2023-11-29T07:13:03.683956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train\n",
    "# # model.load_state_dict(torch.load('CIFAR-model/VGG16.pth'))\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=5e-3)\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4, last_epoch=-1)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     model.to(device)\n",
    "#     running_loss = 0.0\n",
    "#     total_correct = 0\n",
    "#     total_trainset = 0\n",
    " \n",
    "#     for i, (data, labels) in enumerate(trainLoader, 0):\n",
    "#         data = data.to(device)\n",
    "#         outputs = model(data).to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         loss = loss_func(outputs, labels).to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         _, pred = outputs.max(1)\n",
    "#         correct = (pred == labels).sum().item()\n",
    "#         total_correct += correct\n",
    "#         total_trainset += data.shape[0]\n",
    "#         if i % 1000 == 0 and i > 0:\n",
    "#             print(f\"{i}th Training, running_loss={running_loss}\".format(i, running_loss))\n",
    "#             running_loss = 0.0\n",
    "#     test()\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc940928",
   "metadata": {
    "papermill": {
     "duration": 0.017536,
     "end_time": "2023-11-29T07:13:03.755411",
     "exception": false,
     "start_time": "2023-11-29T07:13:03.737875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the model of vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a6bd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:13:03.793863Z",
     "iopub.status.busy": "2023-11-29T07:13:03.793453Z",
     "iopub.status.idle": "2023-11-29T07:13:09.526872Z",
     "shell.execute_reply": "2023-11-29T07:13:09.525184Z"
    },
    "papermill": {
     "duration": 5.75483,
     "end_time": "2023-11-29T07:13:09.529932",
     "exception": false,
     "start_time": "2023-11-29T07:13:03.775102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias', 'features.28.weight', 'features.28.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.6.weight', 'classifier.6.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./vgg16_2.pth',map_location=torch.device('cpu'))\n",
    "print(state_dict.keys())\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3cb84d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:13:09.577690Z",
     "iopub.status.busy": "2023-11-29T07:13:09.576784Z",
     "iopub.status.idle": "2023-11-29T07:13:09.588458Z",
     "shell.execute_reply": "2023-11-29T07:13:09.587140Z"
    },
    "papermill": {
     "duration": 0.037438,
     "end_time": "2023-11-29T07:13:09.591894",
     "exception": false,
     "start_time": "2023-11-29T07:13:09.554456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1806c",
   "metadata": {
    "papermill": {
     "duration": 0.016161,
     "end_time": "2023-11-29T07:13:09.624263",
     "exception": false,
     "start_time": "2023-11-29T07:13:09.608102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# We make a testing for the load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad7df5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:13:09.662246Z",
     "iopub.status.busy": "2023-11-29T07:13:09.661808Z",
     "iopub.status.idle": "2023-11-29T07:13:09.668133Z",
     "shell.execute_reply": "2023-11-29T07:13:09.666713Z"
    },
    "papermill": {
     "duration": 0.03111,
     "end_time": "2023-11-29T07:13:09.671803",
     "exception": false,
     "start_time": "2023-11-29T07:13:09.640693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_gpu_inference_time_and_test_acc(model, test_loader):\n",
    "#     test_data_size = len(testLoader.dataset)\n",
    "#     model = model.cuda()\n",
    "#     # Wam-up\n",
    "#     # Because I sequentially run each cell above, and they includes for loop, I assume the CPU is warmed up\n",
    "#     torch.cuda.synchronize()\n",
    "#     elapsed_time_ms = 0\n",
    "#     start = timer()\n",
    "#     # Start Inference Phase\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, labels in tqdm.tqdm(test_loader):\n",
    "#             imgs, labels = imgs.cuda(), labels.cuda()\n",
    "#             # imgs, labels = imgs, labels\n",
    "#             out = model(imgs)\n",
    "#             predictions = out.argmax(dim=1, keepdim=True)  \n",
    "#             correct += predictions.eq(labels.view_as(predictions)).sum().item()\n",
    "#     accuracy = correct/len(test_loader.dataset)\n",
    "#     print(accuracy)\n",
    "#     # End of inference Phase\n",
    "#     torch.cuda.synchronize()\n",
    "#     end = timer()\n",
    "#     elapsed_time_ms = (end - start) * 1000\n",
    "#     per_sample = elapsed_time_ms/test_data_size\n",
    "#     print(\"GPU Inference time is \" + str(per_sample)+ ' ms')\n",
    "#     return per_sample, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7b2f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:13:09.721264Z",
     "iopub.status.busy": "2023-11-29T07:13:09.720843Z",
     "iopub.status.idle": "2023-11-29T07:13:09.733830Z",
     "shell.execute_reply": "2023-11-29T07:13:09.732442Z"
    },
    "papermill": {
     "duration": 0.046161,
     "end_time": "2023-11-29T07:13:09.736859",
     "exception": false,
     "start_time": "2023-11-29T07:13:09.690698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cpu_inference_time_and_test_acc(model, test_loader):\n",
    "    test_data_size = len(testLoader.dataset)\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    model = model.to(cpu_device)\n",
    "    # Wam-up\n",
    "    # Because I sequentially run each cell above, and they includes for loop, I assume the CPU is warmed up\n",
    "#     torch.cuda.synchronize()\n",
    "    elapsed_time_ms = 0\n",
    "    start = timer()\n",
    "    # Start Inference Phase\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm.tqdm(test_loader):\n",
    "#             imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            imgs, labels = imgs.to(cpu_device), labels.to(cpu_device)\n",
    "            out = model(imgs.float())\n",
    "            predictions = out.argmax(dim=1, keepdim=True)  \n",
    "            correct += predictions.eq(labels.view_as(predictions)).sum().item()\n",
    "#             break\n",
    "    accuracy = correct/len(test_loader.dataset)\n",
    "    print(accuracy)\n",
    "    # End of inference Phase\n",
    "#     torch.cuda.synchronize()\n",
    "    end = timer()\n",
    "    elapsed_time_ms = (end - start) * 1000\n",
    "    per_sample = elapsed_time_ms/test_data_size\n",
    "    print(\"CPU Inference time is \" + str(per_sample)+ ' ms')\n",
    "    return per_sample, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fada27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:13:09.776443Z",
     "iopub.status.busy": "2023-11-29T07:13:09.774298Z",
     "iopub.status.idle": "2023-11-29T07:15:14.325176Z",
     "shell.execute_reply": "2023-11-29T07:15:14.323903Z"
    },
    "papermill": {
     "duration": 124.571191,
     "end_time": "2023-11-29T07:15:14.327490",
     "exception": false,
     "start_time": "2023-11-29T07:13:09.756299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [02:04<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122\n",
      "CPU Inference time is 12.453586680299999 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "cpu_inf_time, acc = get_cpu_inference_time_and_test_acc(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "634b1b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:14.442099Z",
     "iopub.status.busy": "2023-11-29T07:15:14.441609Z",
     "iopub.status.idle": "2023-11-29T07:15:14.448433Z",
     "shell.execute_reply": "2023-11-29T07:15:14.447178Z"
    },
    "papermill": {
     "duration": 0.066509,
     "end_time": "2023-11-29T07:15:14.451028",
     "exception": false,
     "start_time": "2023-11-29T07:15:14.384519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 527.803MB\n"
     ]
    }
   ],
   "source": [
    "size_vgg_bef =os.path.getsize('./vgg16_2.pth')\n",
    "print('model size: {:.3f}MB'.format(size_vgg_bef/1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14644c7",
   "metadata": {
    "papermill": {
     "duration": 0.056117,
     "end_time": "2023-11-29T07:15:14.563097",
     "exception": false,
     "start_time": "2023-11-29T07:15:14.506980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gonna modify the vgg net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fea76b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:14.676697Z",
     "iopub.status.busy": "2023-11-29T07:15:14.676271Z",
     "iopub.status.idle": "2023-11-29T07:15:14.686006Z",
     "shell.execute_reply": "2023-11-29T07:15:14.684862Z"
    },
    "papermill": {
     "duration": 0.070179,
     "end_time": "2023-11-29T07:15:14.688603",
     "exception": false,
     "start_time": "2023-11-29T07:15:14.618424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cpu_inference_time_and_test_acc(model, test_loader):\n",
    "    test_data_size = len(testLoader.dataset)\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    model = model.to(cpu_device)\n",
    "    # Wam-up\n",
    "    # Because I sequentially run each cell above, and they includes for loop, I assume the CPU is warmed up\n",
    "#     torch.cuda.synchronize()\n",
    "    elapsed_time_ms = 0\n",
    "    start = timer()\n",
    "    # Start Inference Phase\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm.tqdm(test_loader):\n",
    "#             imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            imgs, labels = imgs.to(cpu_device), labels.to(cpu_device)\n",
    "            out = model(imgs.float())\n",
    "            predictions = out.argmax(dim=1, keepdim=True)  \n",
    "            correct += predictions.eq(labels.view_as(predictions)).sum().item()\n",
    "#             break\n",
    "    accuracy = correct/len(test_loader.dataset)\n",
    "    print(accuracy)\n",
    "    # End of inference Phase\n",
    "#     torch.cuda.synchronize()\n",
    "    end = timer()\n",
    "    elapsed_time_ms = (end - start) * 1000\n",
    "    per_sample = elapsed_time_ms/test_data_size\n",
    "    print(\"CPU Inference time is \" + str(per_sample)+ ' ms')\n",
    "    return per_sample, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0620867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:14.802117Z",
     "iopub.status.busy": "2023-11-29T07:15:14.801695Z",
     "iopub.status.idle": "2023-11-29T07:15:14.808043Z",
     "shell.execute_reply": "2023-11-29T07:15:14.806888Z"
    },
    "papermill": {
     "duration": 0.066464,
     "end_time": "2023-11-29T07:15:14.810514",
     "exception": false,
     "start_time": "2023-11-29T07:15:14.744050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_gpu_inference_time_and_test_acc(model, test_loader):\n",
    "#     test_data_size = len(testLoader.dataset)\n",
    "#     model = model.cuda()\n",
    "#     # Wam-up\n",
    "#     # Because I sequentially run each cell above, and they includes for loop, I assume the CPU is warmed up\n",
    "#     torch.cuda.synchronize()\n",
    "#     elapsed_time_ms = 0\n",
    "#     start = timer()\n",
    "#     # Start Inference Phase\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, labels in tqdm.tqdm(test_loader):\n",
    "#             imgs, labels = imgs.cuda(), labels.cuda()\n",
    "#             # imgs, labels = imgs, labels\n",
    "#             out = model(imgs)\n",
    "#             predictions = out.argmax(dim=1, keepdim=True)  \n",
    "#             correct += predictions.eq(labels.view_as(predictions)).sum().item()\n",
    "#     accuracy = correct/len(test_loader.dataset)\n",
    "#     print(accuracy)\n",
    "#     # End of inference Phase\n",
    "#     torch.cuda.synchronize()\n",
    "#     end = timer()\n",
    "#     elapsed_time_ms = (end - start) * 1000\n",
    "#     per_sample = elapsed_time_ms/test_data_size\n",
    "#     print(\"GPU Inference time is \" + str(per_sample)+ ' ms')\n",
    "#     return per_sample, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdefe6e",
   "metadata": {
    "papermill": {
     "duration": 0.055191,
     "end_time": "2023-11-29T07:15:14.921129",
     "exception": false,
     "start_time": "2023-11-29T07:15:14.865938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## For static quanlitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "793d1096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:15.034590Z",
     "iopub.status.busy": "2023-11-29T07:15:15.034007Z",
     "iopub.status.idle": "2023-11-29T07:15:15.039609Z",
     "shell.execute_reply": "2023-11-29T07:15:15.038497Z"
    },
    "papermill": {
     "duration": 0.065997,
     "end_time": "2023-11-29T07:15:15.042396",
     "exception": false,
     "start_time": "2023-11-29T07:15:14.976399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.ao.quantization import get_default_qconfig, prepare, convert, fuse_modules\n",
    "from torch.ao.quantization import QConfig, MinMaxObserver, HistogramObserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91367680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:15.155464Z",
     "iopub.status.busy": "2023-11-29T07:15:15.154650Z",
     "iopub.status.idle": "2023-11-29T07:15:15.455273Z",
     "shell.execute_reply": "2023-11-29T07:15:15.454122Z"
    },
    "papermill": {
     "duration": 0.359828,
     "end_time": "2023-11-29T07:15:15.457761",
     "exception": false,
     "start_time": "2023-11-29T07:15:15.097933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "model_to_quantize = copy.deepcopy(model).to(cpu_device)\n",
    "model_to_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7efcca29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:15.571144Z",
     "iopub.status.busy": "2023-11-29T07:15:15.570469Z",
     "iopub.status.idle": "2023-11-29T07:15:18.087485Z",
     "shell.execute_reply": "2023-11-29T07:15:18.086517Z"
    },
    "papermill": {
     "duration": 2.577345,
     "end_time": "2023-11-29T07:15:18.090103",
     "exception": false,
     "start_time": "2023-11-29T07:15:15.512758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "class QuantizedVGG(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(QuantizedVGG, self).__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.vgg = model\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.vgg(x)\n",
    "        return self.dequant(x)\n",
    "\n",
    "model_reload = vgg16(pretrained=True)\n",
    "state_dict = torch.load('./vgg16_2.pth',map_location=torch.device('cpu'))\n",
    "model_reload.load_state_dict(state_dict)\n",
    "model_reload = QuantizedVGG(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab7e7bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:15:18.203484Z",
     "iopub.status.busy": "2023-11-29T07:15:18.202741Z",
     "iopub.status.idle": "2023-11-29T07:29:18.288939Z",
     "shell.execute_reply": "2023-11-29T07:29:18.287608Z"
    },
    "papermill": {
     "duration": 840.146286,
     "end_time": "2023-11-29T07:29:18.291944",
     "exception": false,
     "start_time": "2023-11-29T07:15:18.145658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2084/2084 [13:55<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# gpu_device = torch.device(\"cuda:0\")\n",
    "\n",
    "# model_to_quantize = copy.deepcopy(model).to(gpu_device)\n",
    "model_to_quantize = copy.deepcopy(model_reload)\n",
    "\n",
    "# let the model be the evaluation mode\n",
    "model_to_quantize.eval()\n",
    "\n",
    "# obtain the qualization configeration\n",
    "# qconfig = QConfig(activation=HistogramObserver.with_args(reduce_range=True),\n",
    "#                   weight=MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_affine))\n",
    "\n",
    "# deploy at ARM\n",
    "qconfig = get_default_qconfig(\"qnnpack\")\n",
    "\n",
    "# prepare the model, insert a observer\n",
    "model_to_quantize.qconfig = qconfig\n",
    "model_to_quantize = prepare(model_to_quantize)\n",
    "\n",
    "#  torch.cuda.empty_cache()  # release gpu sources\n",
    "\n",
    "# using dataset to correct\n",
    "with tqdm.tqdm(total=len(trainLoader)) as pbar:\n",
    "    pbar.set_description(\"Processing\")\n",
    "    for data, _ in trainLoader:\n",
    "#         data = data.to(gpu_device)\n",
    "        model_to_quantize(data)\n",
    "        pbar.update(1)\n",
    "#         break\n",
    "        \n",
    "# convert the model\n",
    "model_to_quantize_final = convert(model_to_quantize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2353adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:29:18.794833Z",
     "iopub.status.busy": "2023-11-29T07:29:18.794431Z",
     "iopub.status.idle": "2023-11-29T07:30:13.166002Z",
     "shell.execute_reply": "2023-11-29T07:30:13.164786Z"
    },
    "papermill": {
     "duration": 54.625505,
     "end_time": "2023-11-29T07:30:13.169258",
     "exception": false,
     "start_time": "2023-11-29T07:29:18.543753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:54<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9099\n",
      "CPU Inference time is 5.436205164700004 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "model_to_quantize_final = model_to_quantize_final.to(cpu_device)\n",
    "cpu_inf_time, acc = get_cpu_inference_time_and_test_acc(model_to_quantize_final, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dda03bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:30:13.766783Z",
     "iopub.status.busy": "2023-11-29T07:30:13.766263Z",
     "iopub.status.idle": "2023-11-29T07:30:15.477001Z",
     "shell.execute_reply": "2023-11-29T07:30:15.476179Z"
    },
    "papermill": {
     "duration": 2.022491,
     "end_time": "2023-11-29T07:30:15.479673",
     "exception": false,
     "start_time": "2023-11-29T07:30:13.457182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 132.008MB\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_to_quantize_final.state_dict(), './vgg16_2_aft_sta_qua.pth')\n",
    "size_vgg_aft = os.path.getsize('./vgg16_2_aft_sta_qua.pth')\n",
    "print('model size: {:.3f}MB'.format(size_vgg_aft/1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470fbd6",
   "metadata": {
    "papermill": {
     "duration": 0.28836,
     "end_time": "2023-11-29T07:30:16.055360",
     "exception": false,
     "start_time": "2023-11-29T07:30:15.767000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# For dynamic quantilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7984b3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:30:16.636859Z",
     "iopub.status.busy": "2023-11-29T07:30:16.636454Z",
     "iopub.status.idle": "2023-11-29T07:30:16.842511Z",
     "shell.execute_reply": "2023-11-29T07:30:16.841385Z"
    },
    "papermill": {
     "duration": 0.501095,
     "end_time": "2023-11-29T07:30:16.845392",
     "exception": false,
     "start_time": "2023-11-29T07:30:16.344297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "model_to_dy_quantize = copy.deepcopy(model).to(cpu_device)\n",
    "# model_to_dy_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ed97fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:30:17.495338Z",
     "iopub.status.busy": "2023-11-29T07:30:17.494830Z",
     "iopub.status.idle": "2023-11-29T07:30:17.502706Z",
     "shell.execute_reply": "2023-11-29T07:30:17.501605Z"
    },
    "papermill": {
     "duration": 0.375121,
     "end_time": "2023-11-29T07:30:17.505668",
     "exception": false,
     "start_time": "2023-11-29T07:30:17.130547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_dy_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "286a95b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:30:18.086012Z",
     "iopub.status.busy": "2023-11-29T07:30:18.084959Z",
     "iopub.status.idle": "2023-11-29T07:30:18.090420Z",
     "shell.execute_reply": "2023-11-29T07:30:18.089402Z"
    },
    "papermill": {
     "duration": 0.297235,
     "end_time": "2023-11-29T07:30:18.092882",
     "exception": false,
     "start_time": "2023-11-29T07:30:17.795647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the layer which can be dynamic qconfig\n",
    "# qconfig_spec = {\n",
    "#                 nn.Linear : default_dynamic_qconfig,\n",
    "#                 nn.LSTM : default_dynamic_qconfig,\n",
    "#                 nn.GRU : default_dynamic_qconfig,\n",
    "#                 nn.LSTMCell : default_dynamic_qconfig,\n",
    "#                 nn.RNNCell : default_dynamic_qconfig,\n",
    "#                 nn.GRUCell : default_dynamic_qconfig,\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60c1033c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:30:18.679722Z",
     "iopub.status.busy": "2023-11-29T07:30:18.678969Z",
     "iopub.status.idle": "2023-11-29T07:30:23.516613Z",
     "shell.execute_reply": "2023-11-29T07:30:23.515297Z"
    },
    "papermill": {
     "duration": 5.135269,
     "end_time": "2023-11-29T07:30:23.519706",
     "exception": false,
     "start_time": "2023-11-29T07:30:18.384437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): DynamicQuantizedLinear(in_features=25088, out_features=4096, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): DynamicQuantizedLinear(in_features=4096, out_features=4096, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): DynamicQuantizedLinear(in_features=4096, out_features=1000, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a quantized model instance\n",
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model_to_dy_quantize,  # the original model\n",
    "    {torch.nn.Sequential, torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8)  # the target dtype for quantized weights\n",
    "model_int8.to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a93b1f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:30:24.132619Z",
     "iopub.status.busy": "2023-11-29T07:30:24.132142Z",
     "iopub.status.idle": "2023-11-29T07:31:57.594380Z",
     "shell.execute_reply": "2023-11-29T07:31:57.593146Z"
    },
    "papermill": {
     "duration": 93.75813,
     "end_time": "2023-11-29T07:31:57.598604",
     "exception": false,
     "start_time": "2023-11-29T07:30:23.840474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:33<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9125\n",
      "CPU Inference time is 9.345385786099996 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "model_int8 = model_int8.to(cpu_device)\n",
    "cpu_inf_time, acc = get_cpu_inference_time_and_test_acc(model_int8, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0840a67f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:31:58.251597Z",
     "iopub.status.busy": "2023-11-29T07:31:58.251146Z",
     "iopub.status.idle": "2023-11-29T07:31:59.989174Z",
     "shell.execute_reply": "2023-11-29T07:31:59.987831Z"
    },
    "papermill": {
     "duration": 2.068915,
     "end_time": "2023-11-29T07:31:59.991888",
     "exception": false,
     "start_time": "2023-11-29T07:31:57.922973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 174.086MB\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_int8.state_dict(), './vgg16_2_aft_dyna_qua.pth')\n",
    "size_vgg_aft = os.path.getsize('./vgg16_2_aft_dyna_qua.pth')\n",
    "print('model size: {:.3f}MB'.format(size_vgg_aft/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e7351",
   "metadata": {
    "papermill": {
     "duration": 0.330945,
     "end_time": "2023-11-29T07:32:00.730579",
     "exception": false,
     "start_time": "2023-11-29T07:32:00.399634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 11102,
     "sourceId": 15444,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4075746,
     "sourceId": 7076121,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1157.461603,
   "end_time": "2023-11-29T07:32:02.487897",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-29T07:12:45.026294",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
